{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f39cd4df",
   "metadata": {},
   "source": [
    "# Initial EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67206f-b032-4275-86e4-f6250bc59757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "from pneumonia_detector.preprocess import XrayDataset\n",
    "import random\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a00dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training directories\n",
    "train_dir = \"../data/chest_xray/train/\"\n",
    "normal_train = \"../data/chest_xray/train/NORMAL/\"\n",
    "pneumonia_train = \"../data/chest_xray/train/PNEUMONIA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47709eea-0a9d-4d21-a0e4-1cbdb8ca4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in a random NORMAL and PNEUMONIA image\n",
    "im_normal = Image.open(os.path.join(normal_train, random.choice(os.listdir(normal_train))))\n",
    "print(im_normal.size)\n",
    "im_pneumonia = Image.open(os.path.join(pneumonia_train, random.choice(os.listdir(pneumonia_train))))\n",
    "print(im_pneumonia.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98285ca7-f5b2-4518-8afd-6aaec7e7a87c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot example images\n",
    "classes = [\"NORMAL\", \"PNEUMONIA\"]\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, x_ray in enumerate([im_normal, im_pneumonia]):\n",
    "\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(x_ray)\n",
    "    plt.title(f\"class: {classes[i]} with image size: {x_ray.size}\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e287f946",
   "metadata": {},
   "source": [
    "The image sizes are different. Let's check the sizes of all images in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412eacb2-af9a-4173-9a80-5f3d75037c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = list()\n",
    "for root, dirs, files in os.walk(train_dir):\n",
    "    for filename in files:\n",
    "        im = Image.open((os.path.join(root, filename)))\n",
    "        sizes.append(im.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902a529-ccbe-4568-bc6d-1014aedb22e7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unique sizes\n",
    "set(sizes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f523324",
   "metadata": {},
   "source": [
    "There is lots of variation in image size. They all seem to be grayscale in the training set but there may be colour images in the dataset as well. We will need to manage how we load in the images and what image size to use for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66625316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c24eb-f3fe-4a4a-ab3d-0ae7f6d00332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here we set the image size to 256x256\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ce363-eb52-4bc4-98ee-10da0feae656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can create a Dataset object for loading and preprocessing images\n",
    "xray_train_data = XrayDataset(root_dir=train_dir, transform=train_transforms)\n",
    "len(xray_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90861692-8156-40ea-8cda-db4e6045f04b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to display random images and labels\n",
    "def display_random_images(dataset: torch.utils.data.dataset.Dataset,\n",
    "                          classes: List[str] = None,\n",
    "                          n: int = 3,\n",
    "                          display_shape: bool = True,\n",
    "                         ):\n",
    "    \n",
    "\n",
    "    # Get random sample indexes\n",
    "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
    "\n",
    "    # Setup plot\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # Loop through samples and display random samples \n",
    "    for i, targ_sample in enumerate(random_samples_idx):\n",
    "        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
    "\n",
    "        # Adjust image tensor shape for plotting: [color_channels, height, width] -> [color_channels, height, width]\n",
    "        targ_image_adjust = targ_image.permute(1, 2, 0)\n",
    "\n",
    "        # Plot adjusted samples\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(targ_image_adjust)\n",
    "        plt.axis(\"off\")\n",
    "        if classes:\n",
    "            title = f\"class: {classes[targ_label]}\"\n",
    "            if display_shape:\n",
    "                title = title + f\"\\nshape: {targ_image_adjust.shape}\"\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5291c3cf-c68e-4bcc-9ae0-d5e46376c9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display random images from  Dataset\n",
    "display_random_images(xray_train_data, \n",
    "                      n=3, \n",
    "                      classes=[\"Normal\", \"Pneumonia\"],\n",
    "                     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "566a7b53-4335-4076-be50-b0382ef87e56",
   "metadata": {},
   "source": [
    "We will want to normalize the input images. In order to do that we can calculate the mean and standeard deviations values for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835f239d-a2f0-4886-a48f-baf48270fb65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Dataloader object to feed in training set images for model training.\n",
    "train_dataloader_xray = DataLoader(\n",
    "                                dataset=xray_train_data,\n",
    "                                batch_size=32,\n",
    "                                num_workers=0,\n",
    "                                shuffle=False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab22bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5067098-436f-4902-851e-72b69d2b41a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate the mean and standard deviation for a set of images passed at the batch level\n",
    "def batch_mean_and_sd(loader):\n",
    "    \n",
    "    cnt = 0\n",
    "    fst_moment = torch.empty(3)\n",
    "    snd_moment = torch.empty(3)\n",
    "\n",
    "    for images, _ in loader:\n",
    "        b, _, h, w = images.shape\n",
    "        nb_pixels = b * h * w\n",
    "        sum_ = torch.sum(images, dim=[0, 2, 3])\n",
    "        sum_of_square = torch.sum(images ** 2,\n",
    "                                  dim=[0, 2, 3])\n",
    "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "        snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n",
    "        cnt += nb_pixels\n",
    "\n",
    "    mean, std = fst_moment, torch.sqrt(snd_moment - fst_moment ** 2) \n",
    "          \n",
    "    return mean,std\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b6a0e1-b34a-46c1-b9fe-dfee7ba99705",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = batch_mean_and_sd(train_dataloader_xray)\n",
    "print(\"mean and std: \\n\", mean, std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec5f645c",
   "metadata": {},
   "source": [
    "We can use these values to normalise the image arrays for our training set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42726265",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fa83e95d915810eceec0de0c181d44bddb52533f1e0464b9b927089f12bc89c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
